import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

st.set_page_config(page_title="Final Project")

# Set page title
st.title('Voice Analysis and Comparison of Popular Figures.')

# Introduction
intro_text = """
In an era marked by the rapid advancement of artificial intelligence, the boundaries between reality and simulation continue to blur. One such domain witnessing profound transformations is voice analysis and synthesis. From mimicking iconic personalities to generating entirely new voices, AI-driven technologies are reshaping our perception of audio content.

Our project, titled "Voice Analysis and Comparison of Popular Figures," delves into this fascinating realm, offering a comprehensive exploration of original and AI-generated content. Through a meticulous examination of videos, audios, and quantitative metrics, we aim to uncover the nuances between authentic human expressions and their synthetic counterparts.
"""

# Display Introduction
st.write(intro_text)

# Table of Contents
# Table of Contents
toc_text = """
**Table of Contents:**

1. **Project Overview**
   - [Introduction](#introduction)
   - [Thesis Question](#thesis-question)
   - [Strategic Plan](#strategic-plan)
   - [Project Diagram](#project-diagram)
   - [UI/UX Considerations](#uiux-considerations)
   - [TTS Bot Considerations](#tts-bot-considerations)

2. **Comparative Analysis of Popular Figures**
   - [Donald Trump](#donald-trump)
   - [Snoop Dogg](#snoop-dogg)
   - [Kim Kardashian](#kim-kardashian)
   - [Elon Musk](#elon-musk)
   
3. **Conclusion**
   - [Summary of Findings](#summary-of-findings)
   - [References](#references)
"""

# Display Table of Contents
st.write(toc_text)

st.title("Thesis Question:")
st.write("**Main Goal:** To compare the biometric characteristics of voices of well-known individuals with those generated by AI systems, aiming to discern any distinguishable differences through quantitative measures.")

st.title("Strategic Plan:")

st.write("""
1. **Data Collection and Preparation**: Gather diverse voice recordings of well-known individuals and AI-generated samples. Preprocess data to extract relevant biometric features.

2. **Visual and Audio Comparison**: Provide visual and audio comparisons between original and AI-generated content for each individual.

3. **Quantitative Analysis**: Conduct quantitative analysis on biometric features to compare original and AI-generated voices.

4. **Perception Evaluation**: Gather user feedback on authenticity and similarity between voices through interactive elements.

5. **Conclusion and Implications**: Summarize findings, discuss implications, and address ethical considerations related to voice cloning and privacy.

6. **References and Further Reading**: Provide resources for users interested in exploring the topic further.

7. **User Engagement and Feedback**: Encourage user engagement and iterate based on feedback.
""")

st.title('Project Diagram:')
st.image("./utils/projectdiagram.png")

st.title('UI/UX Considerations:')
st.write("""
Streamlit is ideal for projects involving data, video, audio, and images due to its simplicity, rich media support, seamless integration with DataFrames, interactive visualizations, customizable layouts, fast feedback loop during development, and flexible deployment options. It's a powerful tool for data science projects, making it easy to create interactive web applications with minimal coding effort.
""")

st.title("TTS Bot Considerations")

st.write("""
We've opted for the Parrot AI TTS Bot due to its high-quality synthetic voices and cost-effectiveness. Considerations include accuracy, ethical implications, and user experience.
""")

st.write("For more information, visit [Parrot AI](https://www.tryparrotai.com/).")

st.title('Voice Analysis and Comparison of Popular Figures.')

st.title('Donald Trump')
st.image("./utils/trump/donald-trump--smile.jpg", width=500)

st.title('The Videos for Trump:')

# c1 - is the original voice
# c2 - is the syntetic voice
# c00, c0 , c01 = st.columns([0.5, 10, 0.5])
c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/trump/WhatsApp Video 2024-02-25 at 18.52.28.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    st.write('My fellow Americans, our movement is far from over. In fact, our fight has only just begun.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/trump/Untitled video - Made with Clipchamp.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    st.write('My fellow Americans, our movement is far from over. In fact, our fight has only just begun.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/trump/audio.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/trump/audio (1).mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
  

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/trump/video1416850444.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1, start_time=8)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/trump/video2416850444.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2, start_time=3)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes:**")
    st.write("**/maɪ ˈfɛloʊ əˈmɛrɪkənz, aʊər ˈmuːvmənt ɪz fɑr frɒm ˈoʊvər. ɪn fækt, aʊər faɪt hæz ˈoʊnli dʒʌst bɪˈɡʌn./**")
    st.write("**vowels:**")
    st.write("**/a ˈeɪ əˈɪəɪə eɪ əʊ əˈuː ɪ ɑː ɒ ə ɪ æ æʊ ɑɪ eɪ əʊ ɪ ɒʊ ʌ ɪ ʌɪ ɪˈʌ/**")

df = pd.DataFrame(
    columns=[
        "Name of the Audio",
        "Max Pitch",
        "Min Pitch",
        "Max Intensity",
        "Min Intensity",
        "Duration",
        "Tone (Emotion)",
    ]
)

# Function to add a row to the DataFrame
def add_row(name, max_pitch, min_pitch, max_intensity, min_intensity, duration, tone):
    global df  # Declare df as a global variable
    new_row = pd.DataFrame({
        "Name of the Audio": [name],
        "Max Pitch": [max_pitch],
        "Min Pitch": [min_pitch],
        "Max Intensity": [max_intensity],
        "Min Intensity": [min_intensity],
        "Duration": [duration],
        "Tone (Emotion)": [tone],
    })
    df = pd.concat([df, new_row], ignore_index=True)

# Add some example rows
add_row("Trumps Original Audio", '359.81 Hz', '85.60 Hz', '75.18 dB', '43.41 dB', '7.8 sec', "Happy")
add_row("Trumps Synthetic Audio", '169.09 Hz', '87.84 Hz', '75.02 dB', '34.66 dB', '5.5 sec', "Neutral")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Trump:")
    st.write(df)

    st.title('The coparison in PRAAT for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/trump/2longaudio.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/trump/longaudioone.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Snoop Dogg')
    st.image("./utils/snoop/snoop-smile.jpeg")
    st.title('The Videos for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/snoop/snooporignial - Made with Clipchamp.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/snoop/snoopai - Made with Clipchamp.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/snoop/audio snooprog.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/snoop/audio snoopai.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/snoop/video2005218178.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1, start_time=2)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/snoop/video1005218178.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2, start_time=3)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes:**")
    st.write("**/oʊ waʊ, aɪ θɪŋk ˈhɛvən ɪz ə ˈbjutəfəl pleɪs. aɪ θɪŋk ɪts ˈhæpinəs./**")
    st.write("**vowels:**")
    st.write("**/oʊ aʊ aɪ ɪ ə ɪ ə ɛ ɪ ə aɪ ɪ ɪ ə aɪ ɪ/**")


add_row("Snoops Original Audio", '133.40 Hz', '75.16 Hz', '66.62 dB', '35.21 dB', '3.3 sec', "Neutral")
add_row("Snoops Synthetic Audio", '112.07 Hz', '75.17 Hz', '70.05 dB', '18.91 dB', '2.9 sec', "Sad")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Snoop:")
    st.write(df)

    st.title('The coparison in PRAAT for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/snoop/origheatmapsnoop.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/snoop/aisnoopheatmap.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Kim Kardashian')
    st.image("./utils/kim/kim.jpeg")
    st.title('The Videos for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/kim/1kimorg.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/kim/1kimai.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/kim/(Original Audio) KimK.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/kim/(AI Generated Audio)KimK.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/kim/kimkorg.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/kim/kimkai.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes**")
    st.write("**/ə ˈriəl ˈpæʃən əv maɪn ɪz ˈɡɛtɪŋ ˈrɔŋli əˈkjuzd ˈpipəl aʊt ʌv ˈdʒeɪl/**")
    st.write("**vowels:**")
    st.write("**/ə ɪ eɪ ə ə aɪ aɪ aɪ ɪ ɪ ə ɪ ʌ ʌ ə ɪ eɪ ɪ ɪ/**")

# Data for Kim K
add_row("Kim K - Original Audio", '321.12 Hz', '75.49 Hz', '69.69 dB', '28.44 dB', '3.9', "Neutral")
add_row("Kim K - AI Generated", '280.77 Hz', '75.86 Hz', '82.35 dB', '11.75 dB', '3.59', "Neutral")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Kim:")
    st.write(df)

    st.title('The coparison in PRAAT for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/kim/Original_KimK.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/kim/AI_KimK.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Elon Musk')
    st.image("./utils/elon/elon-smile.jpeg")
    st.title('The Videos for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/elon/1elonorg.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/elon/1elonai.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/elon/(Original Audio) Elon Musk.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/elon/(AI Generated Audio)Elon_musk.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/elon/elonorg.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/elon/elonai.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes**")
    st.write("**/ɡeɪmz wɪl biː ɪndɪˈstɪŋɡwɪʃəbl frʌm riˈæləti ɔːr ˌsɪvɪlaɪˈzeɪʃən wɪl end.**")
    st.write("**vowels:**")
    st.write("**/eɪ ɪ iː ɪ ɪ ə ɪ ɪ ʊ ɪ ɪ ɔː ɪ ɪ aɪ eɪ ɪ aɪ ɪ/**")

# Data for Elon Musk
add_row("Elon Musk - Original Audio", '138.94 Hz', '75.27 Hz', '84.03 dB', '37.13 dB', 'N/A', "Neutral")
add_row("Elon Musk - AI Generated", '481.24 Hz', '73.42 Hz', '69.04 dB', '-325.84 dB', '3.8', "Neutral")
c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Elon:")
    st.write(df)

    st.title('The coparison in PRAAT for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/elon/Original_ElonMusk.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/elon/AI_ElonMusk.png")

c0 = st.columns(1)[0]

with c0:
    st.title("Summary of Findings:")

    st.write(df)
    st.write("The DataFrame captures important acoustic features of audio samples, which are crucial for analyzing speech emotions and voice conversion.")
    st.write("These features align with findings from academic studies on voice conversion and emotional speech analysis.")
    st.write("By understanding and manipulating these features, it's possible to modify emotional expression in speech synthesis and improve emotion recognition systems.")
    st.write("Academic Papers:")
    st.write("Title: \"Voice Conversion and its Application to Speech Synthesis\" by Toda, T., Black, A. W., & Tokuda, K. (2007).")
    st.write("Title: \"Analysis of Emotional Speech: A Review\" by Schuller, B., Batliner, A., Steidl, S., & Seppi, D. (2011).")

# Sample data
data_frequency = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Frequency (Hz)": [359.81, 169.09, 133.40, 112.07, 321.12, 280.77, 138.94, 481.24],
}

data_db = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "dB Level": [75.18, 75.02, 66.62, 70.05, 69.69, 82.35, 84.03, 69.04],
}

data_duration = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Duration (sec)": [7.8, 5.5, 3.3, 2.9, 3.9, 3.59, "N/A", 3.8],
}

data_emotions = {
    "Audio Sample": ["Trump's Original Audio", "Trump's Synthetic Audio", "Snoop's Original Audio", "Snoop's Synthetic Audio", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Emotion": ["Happy", "Neutral", "Neutral", "Sad", "Neutral", "Neutral", "Neutral", "Neutral"],
}

df_frequency = pd.DataFrame(data_frequency)
df_db = pd.DataFrame(data_db)
df_duration = pd.DataFrame(data_duration)
df_emotions = pd.DataFrame(data_emotions)

# Replace "N/A" with NaN in "Duration (sec)" column
df_duration["Duration (sec)"] = pd.to_numeric(df_duration["Duration (sec)"], errors="coerce")

# Merge emotions data with other data
df_merged = pd.merge(df_frequency, df_db, on="Audio Sample")
df_merged = pd.merge(df_merged, df_duration, on="Audio Sample")
df_merged = pd.merge(df_merged, df_emotions, on="Audio Sample")

st.title("Bar Charts and Heatmap:")

# Define layout
c1, c2 = st.columns(2)

# Frequency bar chart
with c1:
    st.subheader("Frequency (Hz)")
    st.bar_chart(df_frequency.set_index("Audio Sample"))

# dB Level bar chart
with c1:
    st.subheader("Duration (sec)")
    st.bar_chart(df_duration.set_index("Audio Sample"))

# Duration bar chart
with c2:
    st.subheader("dB Level")
    st.bar_chart(df_db.set_index("Audio Sample"))

with c2:
    # Display heatmap
    st.subheader("Frequency (Hz) by Emotion")
    heatmap_data = df_merged.pivot(index="Emotion", columns="Audio Sample", values="Frequency (Hz)")
    st.write(sns.heatmap(heatmap_data, annot=True, cmap="YlGnBu", fmt=".2f", linewidths=0.5).figure)

st.write("""
The provided data represents attributes of different audio samples, including frequency (in Hertz), dB level, and duration (in seconds).

- **Frequency (Hz)**: This attribute indicates the frequency of the audio samples in Hertz. Higher values typically represent higher-pitched sounds.
  
- **dB Level**: dB (decibel) level measures the intensity or loudness of the audio samples. Higher dB levels indicate louder sounds.
  
- **Duration (sec)**: This attribute represents the duration of the audio samples in seconds.

The visualizations above display how these attributes vary across different audio samples:

1. **Frequency (Hz) Bar Chart**: This chart shows the frequency (in Hertz) of each audio sample. It helps to visualize the pitch differences between samples.

2. **Duration (sec) Bar Chart**: This chart illustrates the duration (in seconds) of each audio sample. It provides insight into the length of each sample.

3. **dB Level Bar Chart**: This chart displays the dB (decibel) level of each audio sample. It shows the loudness variations among the samples.
""")

# Sample data
data = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic"],
    "Frequency (Hz)": [359.81, 169.09, 133.40, 112.07],
    "dB Level": [75.18, 75.02, 66.62, 70.05],
    "Duration (sec)": [7.8, 5.5, 3.3, 2.9],
}

df = pd.DataFrame(data)

# Compute correlation matrix
corr = df.drop(columns=["Audio Sample"]).corr()

# Create heatmap
st.subheader("Correlation Heatmap")
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5, square=True)
fig = plt.gcf()  # Get current figure
st.pyplot(fig)

st.write("""
A correlation heatmap visualizes the relationships between variables in a dataset. Darker colors indicate stronger correlations, while lighter colors indicate weaker or no correlations. Positive correlations (values closer to 1) mean variables tend to increase together, negative correlations (values closer to -1) mean one variable tends to increase as the other decreases, and correlations close to zero mean no linear relationship. In our case, the heatmap shows how attributes like frequency, dB level, and duration are related across different audio samples.
""")

c0 = st.columns(1)[0]

with c0:
    st.title("In conclusion:")
    st.write("""
        This project compares original and AI-generated content, including videos, audios, and quantitative metrics. Visualizations and analysis reveal similarities and differences.
        Videos show visual comparisons, while audios analyze acoustic features like pitch, intensity, and emotion.
        Quantitative metrics in the DataFrame support analysis, aligning with academic findings.
        The project emphasizes considering both visual and acoustic features in comparisons, showcasing AI's impact on speech analysis and synthesis.
        As a result, it was concluded that further testing with additional audio samples from the same individual is necessary for a more comprehensive analysis.
        """)

with c0:
    st.title("References:")
    st.write("Academic Papers:")
    st.write("Title: \"Voice Conversion and its Application to Speech Synthesis\" by Toda, T., Black, A. W., & Tokuda, K. (2007).")
    st.write("Title: \"Analysis of Emotional Speech: A Review\" by Schuller, B., Batliner, A., Steidl, S., & Seppi, D. (2011).")
    st.write("AI Voice Generator: https://www.tryparrotai.com/ai-voice-generator/")
    st.write("Dependencies: streamlit, pandas, matplotlib.")
