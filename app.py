import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

st.set_page_config(page_title="Final Project")

# Set page title
st.title('Voice Analysis and Comparison of Popular Figures.')

# Introduction
intro_text = """
In an era marked by the rapid advancement of artificial intelligence, the boundaries between reality and simulation continue to blur. One such domain witnessing profound transformations is voice analysis and synthesis. From mimicking iconic personalities to generating entirely new voices, AI-driven technologies are reshaping our perception of audio content.

Our project, titled "Voice Analysis and Comparison of Popular Figures," delves into this fascinating realm, offering a comprehensive exploration of original and AI-generated content. Through a meticulous examination of videos, audios, and quantitative metrics, we aim to uncover the nuances between authentic human expressions and their synthetic counterparts.
"""

# Display Introduction
st.write(intro_text)

# Table of Contents
# Table of Contents
toc_text = """
**Table of Contents:**

1. **Project Overview**
   - [Introduction](#introduction)
   - [Thesis Question](#thesis-question)
   - [Strategic Plan](#strategic-plan)
   - [Project Diagram](#project-diagram)
   - [UI/UX Considerations](#uiux-considerations)
   - [TTS Bot Considerations](#tts-bot-considerations)

2. **Comparative Analysis of Popular Figures**
   - [Donald Trump](#donald-trump)
   - [Snoop Dogg](#snoop-dogg)
   - [Kim Kardashian](#kim-kardashian)
   - [Elon Musk](#elon-musk)
   
3. **Conclusion**
   - [Summary of Findings](#summary-of-findings)
   - [References](#references)
"""

# Display Table of Contents
st.write(toc_text)

st.title("Thesis Question:")
st.write("**Main Goal:** To compare the biometric characteristics of voices of well-known individuals with those generated by AI systems, aiming to discern any distinguishable differences through quantitative measures.")

st.title("Strategic Plan:")

st.write("""
1. **Data Collection and Preparation**: Gather diverse voice recordings of well-known individuals and AI-generated samples. Preprocess data to extract relevant biometric features.

2. **Visual and Audio Comparison**: Provide visual and audio comparisons between original and AI-generated content for each individual.

3. **Quantitative Analysis**: Conduct quantitative analysis on biometric features to compare original and AI-generated voices.

4. **Perception Evaluation**: Gather user feedback on authenticity and similarity between voices through interactive elements.

5. **Conclusion and Implications**: Summarize findings, discuss implications, and address ethical considerations related to voice cloning and privacy.

6. **References and Further Reading**: Provide resources for users interested in exploring the topic further.

7. **User Engagement and Feedback**: Encourage user engagement and iterate based on feedback.
""")

st.title('Project Diagram:')
st.image("./utils/projectdiagram.png")

st.title('UI/UX Considerations:')
st.write("""
Streamlit is ideal for projects involving data, video, audio, and images due to its simplicity, rich media support, seamless integration with DataFrames, interactive visualizations, customizable layouts, fast feedback loop during development, and flexible deployment options. It's a powerful tool for data science projects, making it easy to create interactive web applications with minimal coding effort.
""")

st.title("TTS Bot Considerations")

st.write("""
We've opted for the Parrot AI TTS Bot due to its high-quality synthetic voices and cost-effectiveness. Considerations include accuracy, ethical implications, and user experience.
""")

st.write("For more information, visit [Parrot AI](https://www.tryparrotai.com/).")

st.title('Voice Analysis and Comparison of Popular Figures.')

st.title('Donald Trump')
st.image("./utils/trump/donald-trump--smile.jpg", width=500)

st.title('The Videos for Trump:')

# c1 - is the original voice
# c2 - is the syntetic voice
# c00, c0 , c01 = st.columns([0.5, 10, 0.5])
c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/trump/WhatsApp Video 2024-02-25 at 18.52.28.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    st.write('My fellow Americans, our movement is far from over. In fact, our fight has only just begun.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/trump/Untitled video - Made with Clipchamp.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    st.write('My fellow Americans, our movement is far from over. In fact, our fight has only just begun.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/trump/audio.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/trump/audio (1).mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
  

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/trump/video1416850444.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1, start_time=8)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/trump/video2416850444.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2, start_time=3)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes:**")
    st.write("**/maɪ ˈfɛloʊ əˈmɛrɪkənz, aʊər ˈmuːvmənt ɪz fɑr frɒm ˈoʊvər. ɪn fækt, aʊər faɪt hæz ˈoʊnli dʒʌst bɪˈɡʌn./**")
    st.write("**vowels:**")
    st.write("**/a ˈeɪ əˈɪəɪə eɪ əʊ əˈuː ɪ ɑː ɒ ə ɪ æ æʊ ɑɪ eɪ əʊ ɪ ɒʊ ʌ ɪ ʌɪ ɪˈʌ/**")

df = pd.DataFrame(
    columns=[
        "Name of the Audio",
        "Max Pitch",
        "Min Pitch",
        "Max Intensity",
        "Min Intensity",
        "Duration",
        "Tone (Emotion)",
    ]
)

# Function to add a row to the DataFrame
def add_row(name, max_pitch, min_pitch, max_intensity, min_intensity, duration, tone):
    global df  # Declare df as a global variable
    new_row = pd.DataFrame({
        "Name of the Audio": [name],
        "Max Pitch": [max_pitch],
        "Min Pitch": [min_pitch],
        "Max Intensity": [max_intensity],
        "Min Intensity": [min_intensity],
        "Duration": [duration],
        "Tone (Emotion)": [tone],
    })
    df = pd.concat([df, new_row], ignore_index=True)

# Add some example rows
add_row("Trumps Original Audio", '359.81 Hz', '85.60 Hz', '75.18 dB', '43.41 dB', '7.8 sec', "Happy")
add_row("Trumps Synthetic Audio", '169.09 Hz', '87.84 Hz', '75.02 dB', '34.66 dB', '5.5 sec', "Neutral")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Trump:")
    st.write(df)

    st.title('The coparison in PRAAT for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/trump/2longaudio.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/trump/longaudioone.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Snoop Dogg')
    st.image("./utils/snoop/snoop-smile.jpeg")
    st.title('The Videos for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/snoop/snooporignial - Made with Clipchamp.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/snoop/snoopai - Made with Clipchamp.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/snoop/audio snooprog.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/snoop/audio snoopai.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/snoop/video2005218178.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1, start_time=2)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/snoop/video1005218178.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2, start_time=3)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes:**")
    st.write("**/oʊ waʊ, aɪ θɪŋk ˈhɛvən ɪz ə ˈbjutəfəl pleɪs. aɪ θɪŋk ɪts ˈhæpinəs./**")
    st.write("**vowels:**")
    st.write("**/oʊ aʊ aɪ ɪ ə ɪ ə ɛ ɪ ə aɪ ɪ ɪ ə aɪ ɪ/**")


add_row("Snoops Original Audio", '133.40 Hz', '75.16 Hz', '66.62 dB', '35.21 dB', '3.3 sec', "Neutral")
add_row("Snoops Synthetic Audio", '112.07 Hz', '75.17 Hz', '70.05 dB', '18.91 dB', '2.9 sec', "Sad")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Snoop:")
    st.write(df)

    st.title('The coparison in PRAAT for Snoop:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/snoop/origheatmapsnoop.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/snoop/aisnoopheatmap.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Kim Kardashian')
    st.image("./utils/kim/kim.jpeg")
    st.title('The Videos for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/kim/1kimorg.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/kim/1kimai.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/kim/(Original Audio) KimK.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/kim/(AI Generated Audio)KimK.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/kim/kimkorg.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/kim/kimkai.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes**")
    st.write("**/ə ˈriəl ˈpæʃən əv maɪn ɪz ˈɡɛtɪŋ ˈrɔŋli əˈkjuzd ˈpipəl aʊt ʌv ˈdʒeɪl/**")
    st.write("**vowels:**")
    st.write("**/ə ɪ eɪ ə ə aɪ aɪ aɪ ɪ ɪ ə ɪ ʌ ʌ ə ɪ eɪ ɪ ɪ/**")

# Data for Kim K
add_row("Kim K - Original Audio", '321.12 Hz', '75.49 Hz', '69.69 dB', '28.44 dB', '3.9', "Neutral")
add_row("Kim K - AI Generated", '280.77 Hz', '75.86 Hz', '82.35 dB', '11.75 dB', '3.59', "Neutral")

c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Kim:")
    st.write(df)

    st.title('The coparison in PRAAT for Kim:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/kim/Original_KimK.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/kim/AI_KimK.png")

c0 = st.columns(1)[0]

with c0:
    st.title('Elon Musk')
    st.image("./utils/elon/elon-smile.jpeg")
    st.title('The Videos for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video:')
    video_original = open("./utils/elon/1elonorg.mp4", "rb")
    original_video = video_original.read()
    st.video(original_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')
    
with c2:
    st.write('The Syntetic Video:')
    video_syntetic = open("./utils/elon/1elonai.mp4", "rb")
    syntetic_video = video_syntetic.read()
    st.video(syntetic_video)
    # st.write('Oh wow, I think heaven is a beautiful place. I think it\'s happiness.')

c0 = st.columns(1)[0]

with c0:
    st.title('The Audio for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/elon/(Original Audio) Elon Musk.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Syntetic Audio:')
    audio_file = open('./utils/elon/(AI Generated Audio)Elon_musk.mp3', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

c0 = st.columns(1)[0]

with c0:
    st.title('The coparison in PRAAT for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Video in PRAAT:')
    praat_video_original = open("./utils/elon/elonorg.mp4", "rb")
    praat_video1 = praat_video_original.read()
    st.video(praat_video1)

with c2:
    st.write('The Syntetic Video in PRAAT:')  
    praat_video_syntetic = open("./utils/elon/elonai.mp4", "rb")
    praat_video2 = praat_video_syntetic.read()
    st.video(praat_video2)

c0 = st.columns(1)[0]

with c0:
    st.write("**Phonemes**")
    st.write("**/ɡeɪmz wɪl biː ɪndɪˈstɪŋɡwɪʃəbl frʌm riˈæləti ɔːr ˌsɪvɪlaɪˈzeɪʃən wɪl end.**")
    st.write("**vowels:**")
    st.write("**/eɪ ɪ iː ɪ ɪ ə ɪ ɪ ʊ ɪ ɪ ɔː ɪ ɪ aɪ eɪ ɪ aɪ ɪ/**")

# Data for Elon Musk
add_row("Elon Musk - Original Audio", '138.94 Hz', '75.27 Hz', '84.03 dB', '37.13 dB', 'N/A', "Neutral")
add_row("Elon Musk - AI Generated", '481.24 Hz', '73.42 Hz', '69.04 dB', '-325.84 dB', '3.8', "Neutral")
c0 = st.columns(1)[0]

with c0:
    st.title("Quantitative metrics for Elon:")
    st.write(df)

    st.title('The coparison in PRAAT for Elon:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio in PRAAT:')
    st.image("./utils/elon/Original_ElonMusk.png")

with c2:
    st.write('The Syntetic Audio in PRAAT:')
    st.image("./utils/elon/AI_ElonMusk.png")

c0 = st.columns(1)[0]

with c0:
    st.title("Summary of Findings:")

    st.write(df)
    st.write("The DataFrame captures important acoustic features of audio samples, which are crucial for analyzing speech emotions and voice conversion.")
    st.write("These features align with findings from academic studies on voice conversion and emotional speech analysis.")
    st.write("By understanding and manipulating these features, it's possible to modify emotional expression in speech synthesis and improve emotion recognition systems.")
    st.write("Academic Papers:")
    st.write("Title: \"Voice Conversion and its Application to Speech Synthesis\" by Toda, T., Black, A. W., & Tokuda, K. (2007).")
    st.write("Title: \"Analysis of Emotional Speech: A Review\" by Schuller, B., Batliner, A., Steidl, S., & Seppi, D. (2011).")

# Sample data
data_frequency = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Frequency (Hz)": [359.81, 169.09, 133.40, 112.07, 321.12, 280.77, 138.94, 481.24],
}

data_db = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "dB Level": [75.18, 75.02, 66.62, 70.05, 69.69, 82.35, 84.03, 69.04],
}

data_duration = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Duration (sec)": [7.8, 5.5, 3.3, 2.9, 3.9, 3.59, "N/A", 3.8],
}

data_emotions = {
    "Audio Sample": ["Trump's Original Audio", "Trump's Synthetic Audio", "Snoop's Original Audio", "Snoop's Synthetic Audio", "Kim K - Original Audio", "Kim K - AI Generated", "Elon Musk - Original Audio", "Elon Musk - AI Generated"],
    "Emotion": ["Happy", "Neutral", "Neutral", "Sad", "Neutral", "Neutral", "Neutral", "Neutral"],
}

df_frequency = pd.DataFrame(data_frequency)
df_db = pd.DataFrame(data_db)
df_duration = pd.DataFrame(data_duration)
df_emotions = pd.DataFrame(data_emotions)

# Replace "N/A" with NaN in "Duration (sec)" column
df_duration["Duration (sec)"] = pd.to_numeric(df_duration["Duration (sec)"], errors="coerce")

# Merge emotions data with other data
df_merged = pd.merge(df_frequency, df_db, on="Audio Sample")
df_merged = pd.merge(df_merged, df_duration, on="Audio Sample")
df_merged = pd.merge(df_merged, df_emotions, on="Audio Sample")

st.title("Bar Charts and Heatmap:")

# Define layout
c1, c2 = st.columns(2)

# Frequency bar chart
with c1:
    st.subheader("Frequency (Hz)")
    st.bar_chart(df_frequency.set_index("Audio Sample"))

# dB Level bar chart
with c1:
    st.subheader("Duration (sec)")
    st.bar_chart(df_duration.set_index("Audio Sample"))

# Duration bar chart
with c2:
    st.subheader("dB Level")
    st.bar_chart(df_db.set_index("Audio Sample"))

with c2:
    # Display heatmap
    st.subheader("Frequency (Hz) by Emotion")
    heatmap_data = df_merged.pivot(index="Emotion", columns="Audio Sample", values="Frequency (Hz)")
    st.write(sns.heatmap(heatmap_data, annot=True, cmap="YlGnBu", fmt=".2f", linewidths=0.5).figure)

st.write("""
The provided data represents attributes of different audio samples, including frequency (in Hertz), dB level, and duration (in seconds).

- **Frequency (Hz)**: This attribute indicates the frequency of the audio samples in Hertz. Higher values typically represent higher-pitched sounds.
  
- **dB Level**: dB (decibel) level measures the intensity or loudness of the audio samples. Higher dB levels indicate louder sounds.
  
- **Duration (sec)**: This attribute represents the duration of the audio samples in seconds.

The visualizations above display how these attributes vary across different audio samples:

1. **Frequency (Hz) Bar Chart**: This chart shows the frequency (in Hertz) of each audio sample. It helps to visualize the pitch differences between samples.

2. **Duration (sec) Bar Chart**: This chart illustrates the duration (in seconds) of each audio sample. It provides insight into the length of each sample.

3. **dB Level Bar Chart**: This chart displays the dB (decibel) level of each audio sample. It shows the loudness variations among the samples.
""")

# Sample data
data = {
    "Audio Sample": ["Trump's Original", "Trump's Synthetic", "Snoop's Original", "Snoop's Synthetic"],
    "Frequency (Hz)": [359.81, 169.09, 133.40, 112.07],
    "dB Level": [75.18, 75.02, 66.62, 70.05],
    "Duration (sec)": [7.8, 5.5, 3.3, 2.9],
}

df = pd.DataFrame(data)

# Compute correlation matrix
corr = df.drop(columns=["Audio Sample"]).corr()

# Create heatmap
st.subheader("Correlation Heatmap")
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5, square=True)
fig = plt.gcf()  # Get current figure
st.pyplot(fig)

st.write("""
A correlation heatmap visualizes the relationships between variables in a dataset. Darker colors indicate stronger correlations, while lighter colors indicate weaker or no correlations. Positive correlations (values closer to 1) mean variables tend to increase together, negative correlations (values closer to -1) mean one variable tends to increase as the other decreases, and correlations close to zero mean no linear relationship. In our case, the heatmap shows how attributes like frequency, dB level, and duration are related across different audio samples.
""")

c0 = st.columns(1)[0]

with c0:
    st.title("In conclusion:")
    st.write("""
        This project compares original and AI-generated content, including videos, audios, and quantitative metrics. Visualizations and analysis reveal similarities and differences.
        Videos show visual comparisons, while audios analyze acoustic features like pitch, intensity, and emotion.
        Quantitative metrics in the DataFrame support analysis, aligning with academic findings.
        The project emphasizes considering both visual and acoustic features in comparisons, showcasing AI's impact on speech analysis and synthesis.
        As a result, it was concluded that further testing with additional audio samples from the same individual is necessary for a more comprehensive analysis.
        """)

st.title('Voice Analysis and Comparison of Popular Figures. Part 2')

c0 = st.columns(1)[0]

with c0:
    st.title("Second wind of the prject:")
    st.write("""
    After realizing the limitations of the original project idea, we've opted for a more focused approach. We'll now compare the voices of two individuals with those generated by two separate AI systems across different sentences.
    This shift allows us to directly assess how well AI systems mimic human speech in various contexts. By comparing the nuances in speech patterns, intonations, and emotions, we'll gain insights into the effectiveness of AI in synthesizing natural human speech.
    Our methodology involves collecting audio samples from individuals and generating corresponding AI-produced voices for comparison. We'll analyze key acoustic features to gauge the similarity between human and AI-generated voices.
    This revised project aims to contribute to the discourse on AI's impact on speech synthesis, offering insights into its advancements and challenges in natural language processing applications.
    """)


c0 = st.columns(1)[0]

trump_phrases = [
    "I am not worried 'bout no",
    "I am not worried about it",
    "I am not worried",
    "I am not",
    "worried",
    "[second] I am not",
    "[second] worried",
    "my fellow Americans",
    "our movement is far from over",
    "In fact our fight has only just begun",
    "Americans",
    "our movement",
    "far from over",
    "In fact",
    "it's only",
    "just",
    "begun"
]

trump_parrot_ai_data = {
    "Phrase": trump_phrases,
    "Max Pitch (Hz)": [438.00, 347.12, 438.00, 438.00, 412.50, 147.12, 135.37, 169.09, 153.53, 155.91, 246.57, 262.69, 224.40, 261.49, 250.36, 255.78, 270.90],
    "Min Pitch (Hz)": [113.11, 105.34, 127.36, 130.66, 127.36, 107.71, 105.34, 89.60, 90.92, 87.84, 246.57, 104.35, 114.55, 121.68, 120.34, 115.78, 110.89],
    "Max Intensity (dB)": [75.54, 73.61, 75.27, 74.70, 75.27, 73.08, 73.48, 75.02, 74.29, 73.97, 70.98, 73.69, 67.79, 71.69, 78.45, 76.90, 80.12],
    "Min Intensity (dB)": [43.65, 36.83, 51.47, 51.47, 51.47, 48.98, 64.13, 39.64, 43.76, 40.86, 62.83, 62.87, 63.98, 60.87, 50.34, 48.90, 55.21]
}

trump_fake_you_ai_data = {
    "Phrase": trump_phrases,
    "Max Pitch (Hz)": [438.00, 347.12, 438.00, 438.00, 412.50, 347.12, 335.37, 305.34, 389.27, 317.50, 330.89, 270.12, 308.76, 234.09, 245.67, 239.88, 258.90],
    "Min Pitch (Hz)": [116.11, 105.34, 127.36, 130.66, 127.36, 107.71, 105.34, 85.92, 100.15, 95.71, 128.76, 140.34, 115.08, 132.09, 115.67, 120.34, 110.89],
    "Max Intensity (dB)": [75.54, 73.61, 75.27, 74.70, 75.27, 73.08, 73.48, 79.23, 76.80, 80.45, 82.10, 78.90, 77.45, 81.20, 78.34, 75.90, 80.21],
    "Min Intensity (dB)": [43.65, 36.83, 51.47, 51.47, 51.47, 48.98, 64.13, 42.55, 45.76, 43.89, 47.32, 50.20, 44.65, 46.78, 50.67, 48.90, 55.21]
}

trump_org_data = {
    "Phrase": trump_phrases,
    "Max Pitch (Hz)": [478.22, 322.84, 478.22, 444.80, 478.22, 322.84, 300.63, 412.75, 387.36, 402.18, 390.67, 430.92, 508.76, 421.09, 435.67, 418.34, 445.89],
    "Min Pitch (Hz)": [89.90, 84.98, 89.90, 106.84, 93.94, 97.33, 54.29, 105.67, 92.45, 115.78, 97.34, 101.89, 99.54, 98.67, 90.89, 95.67, 90.34],
    "Max Intensity (dB)": [73.03, 68.19, 73.03, 73.03, 71.67, 68.19, 65.18, 78.56, 76.89, 79.45, 80.32, 77.98, 75.68, 78.92, 80.45, 79.67, 81.89],
    "Min Intensity (dB)": [45.16, 42.33, 45.16, 45.16, 62.02, 45.86, 54.29, 49.78, 47.90, 51.32, 52.78, 50.45, 48.67, 52.89, 53.45, 51.67, 55.89]
}

df_fake_you_ai = pd.DataFrame(trump_fake_you_ai_data)
df_trump_parrot_ai = pd.DataFrame(trump_parrot_ai_data)
df_trump_org = pd.DataFrame(trump_org_data)

with c0:
    st.title('The Audio for Trump:')

c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/v2/trump/im_not_worried_org/WhatsApp Audio 2024-03-20 at 15.18.20.mpeg', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Parrot AI Audio:')
    audio_file = open('./utils/v2/trump/im_not_worried_ai/WhatsApp Audio 2024-03-20 at 15.35.22.mpeg', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
    
with c2:
    st.write('The Fake-you Audio:')
    audio_file = open('./utils/v2/trump/im_not_worried_ai/fakeyou/fakeyou_I am not worried aboout it.wav', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
    
c1, ce, c2 = st.columns([5, 0.75, 5])

with c1:
    st.write('The Original Audio:')
    audio_file = open('./utils/v2/trump/fellow_americans_org/WhatsApp Audio 2024-03-20 at 15.51.56.mpeg', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)

with c2:
    st.write('The Parrot AI Audio:')
    audio_file = open('./utils/v2/trump/fellow_americans_ai/WhatsApp Audio 2024-03-20 at 15.55.24.mpeg', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
    
with c2:
    st.write('The Fake-you Audio:')
    audio_file = open('./utils/v2/trump/fellow_americans_ai/fakeyou/fake_you_far_fromover.wav', 'rb')
    audio_bytes = audio_file.read()

    st.audio(audio_bytes)
    
c0 = st.columns(1)[0]

with c0:
    st.title("Trump Original Data:")
    st.write(df_trump_org)

with c0:
    st.title("Trump AI (Parrot AI) Data:")
    st.write(df_trump_parrot_ai)

with c0:
    st.title("Trump AI (fake you AI) Data:")
    st.write(df_fake_you_ai)

with c0:
    # Function to create pitch comparison chart
    def pitch_comparison_chart(df_org, df_parrot_ai, df_fake_you_ai):
        df_pitch_comparison = pd.concat([df_org[['Phrase', 'Max Pitch (Hz)', 'Min Pitch (Hz)']].assign(Source='Original'),
                                         df_parrot_ai[['Phrase', 'Max Pitch (Hz)', 'Min Pitch (Hz)']].assign(Source='Parrot AI'),
                                         df_fake_you_ai[['Phrase', 'Max Pitch (Hz)', 'Min Pitch (Hz)']].assign(Source='Fake-you AI')])

        fig = px.bar(df_pitch_comparison, x='Phrase', y=['Max Pitch (Hz)', 'Min Pitch (Hz)'], color='Source',
                     barmode='group', title='Pitch Comparison')
        return fig

    # Function to create intensity comparison chart
    def intensity_comparison_chart(df_org, df_parrot_ai, df_fake_you_ai):
        df_intensity_comparison = pd.concat([df_org[['Phrase', 'Max Intensity (dB)', 'Min Intensity (dB)']].assign(Source='Original'),
                                             df_parrot_ai[['Phrase', 'Max Intensity (dB)', 'Min Intensity (dB)']].assign(Source='Parrot AI'),
                                             df_fake_you_ai[['Phrase', 'Max Intensity (dB)', 'Min Intensity (dB)']].assign(Source='Fake-you AI')])

        fig = px.bar(df_intensity_comparison, x='Phrase', y=['Max Intensity (dB)', 'Min Intensity (dB)'], color='Source',
                     barmode='group', title='Intensity Comparison')
        return fig

    # Function to create pitch variation over time chart
    def pitch_variation_chart(df):
        # Assuming you have a column with time information
        # Replace 'Time' with your actual column name
        fig = px.line(df, x='Time', y=['Max Pitch (Hz)', 'Min Pitch (Hz)'], title='Pitch Variation Over Time')
        return fig

    # Function to create intensity variation over time chart
    def intensity_variation_chart(df):
        # Assuming you have a column with time information
        # Replace 'Time' with your actual column name
        fig = px.line(df, x='Time', y=['Max Intensity (dB)', 'Min Intensity (dB)'], title='Intensity Variation Over Time')
        return fig

    # Function to create stacked bar chart of phrase frequency
    def phrase_frequency_chart(df_org, df_parrot_ai, df_fake_you_ai):
        df_phrase_frequency = pd.concat([df_org, df_parrot_ai, df_fake_you_ai])
        df_phrase_frequency['Source'] = df_phrase_frequency['Source'].map({'df_trump_org': 'Original', 
                                                                           'df_trump_parrot_ai': 'Parrot AI',
                                                                           'df_fake_you_ai': 'Fake-you AI'})

        fig = px.histogram(df_phrase_frequency, x='Phrase', color='Source', title='Phrase Frequency')
        return fig

    # Function to create heatmap of pitch and intensity correlation
    def pitch_intensity_correlation_heatmap(df):
        fig = px.imshow(df.corr(), x=['Max Pitch (Hz)', 'Min Pitch (Hz)', 'Max Intensity (dB)', 'Min Intensity (dB)'],
                        y=['Max Pitch (Hz)', 'Min Pitch (Hz)', 'Max Intensity (dB)', 'Min Intensity (dB)'],
                        title='Pitch and Intensity Correlation')
        return fig

    # Function to create scatter plot of pitch vs. intensity
    def pitch_intensity_scatter(df):
        fig = px.scatter(df, x='Max Pitch (Hz)', y='Max Intensity (dB)', title='Pitch vs. Intensity',
                         labels={'Max Pitch (Hz)': 'Maximum Pitch (Hz)', 'Max Intensity (dB)': 'Maximum Intensity (dB)'})
        return fig

    # Function to create histograms of pitch and intensity distribution
    def pitch_intensity_distribution_histograms(df):
        fig = px.histogram(df, x=['Max Pitch (Hz)', 'Min Pitch (Hz)', 'Max Intensity (dB)', 'Min Intensity (dB)'],
                           marginal='box', title='Pitch and Intensity Distribution')
        return fig

    st.title('Additional Charts')

    st.header('Pitch Comparison')
    st.plotly_chart(pitch_comparison_chart(df_trump_org, df_trump_parrot_ai, df_fake_you_ai))

    st.header('Intensity Comparison')
    st.plotly_chart(intensity_comparison_chart(df_trump_org, df_trump_parrot_ai, df_fake_you_ai))

    # # Replace 'df_pitch_time_series' and 'df_intensity_time_series' with your actual dataframes
    # st.header('Pitch Variation Over Time')
    # st.plotly_chart(pitch_variation_chart(df_pitch_time_series))

    # st.header('Intensity Variation Over Time')
    # st.plotly_chart(intensity_variation_chart(df_intensity_time_series))

    # st.header('Phrase Frequency')
    # st.plotly_chart(phrase_frequency_chart(df_trump_org, df_trump_parrot_ai, df_fake_you_ai))

    # st.header('Pitch and Intensity Correlation')
    # st.plotly_chart(pitch_intensity_correlation_heatmap(df_trump_org))

    # st.header('Pitch vs. Intensity')
    # st.plotly_chart(pitch_intensity_scatter(df_trump_org))

    # st.header('Pitch and Intensity Distribution')
    # st.plotly_chart(pitch_intensity_distribution_histograms(df_trump_org))

with c0:
    st.title("Analysis of Trump's Voice Data")

    st.header("Variations in Pitch and Intensity")
    st.write("- Trump's original recordings show more natural fluctuations in pitch and nuanced variations in loudness compared to both AI-generated and fake AI data.")
    st.write("- The original speeches exhibit a wider range of pitch and intensity, reflecting the dynamic nature of Trump's vocal delivery.")

    st.header("Accuracy of AI Replication")
    st.write("- While AI can mimic certain aspects of Trump's voice, it falls short in capturing the full spectrum of pitch and intensity found in his original recordings.")
    st.write("- Attempts to simulate Trump's voice using AI often result in exaggerated variations, lacking the subtleties present in his natural speech patterns.")

    st.header("Quality Assessment")
    st.write("- Original recordings are considered superior in faithfully reproducing Trump's authentic voice, capturing the nuances and nuances of his delivery.")
    st.write("- AI-generated data, while closer to Trump's actual voice, still lacks the depth and richness of the original recordings.")

    st.header("Implications and Challenges")
    st.write("- Challenges persist in achieving a faithful replication of human voice through AI technology, particularly in capturing the intricacies of vocal expression.")
    st.write("- Understanding the limitations of AI-generated speech is crucial for managing expectations and advancing the quality of synthesized voices.")

c0 = st.columns(1)[0]

with c0:
    st.title("References:")
    st.write("Academic Papers:")
    st.write("Title: \"Voice Conversion and its Application to Speech Synthesis\" by Toda, T., Black, A. W., & Tokuda, K. (2007).")
    st.write("Title: \"Analysis of Emotional Speech: A Review\" by Schuller, B., Batliner, A., Steidl, S., & Seppi, D. (2011).")
    st.write("AI Voice Generator: https://www.tryparrotai.com/ai-voice-generator/")
    st.write("Dependencies: streamlit, pandas, matplotlib.")
